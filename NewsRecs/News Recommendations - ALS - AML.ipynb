{
    "cells": [{
        "cell_type": "markdown",
        "source": ["### News Recommendation ALS w/ AML Example Databricks Notebook\n##### by Daniel Ciborowski, dciborow@microsoft.com\n\n##### Copyright (c) Microsoft Corporation. All rights reserved.\n\n##### Licensed under the MIT License.\n\n##### Setup\n1. Create new Cluster, DB 4.1, Spark 2.3.0, Python3\n1. (Optional for Ranking Metrics) From Maven add to cluster the following jar: Azure:mmlspark:0.15\n1. Cosmos DB Uber Jar - https://repo1.maven.org/maven2/com/microsoft/azure/azure-cosmosdb-spark_2.3.0_2.11/1.2.7/azure-cosmosdb-spark_2.3.0_2.11-1.2.7-uber.jar\n\n##### This notebook is broken down into four sections.\n1. Service Creation\n1. Training\n1. Scoring\n1. Operationalization\n\n##### The following Azure services will be deployed into a new or existing resource group.\n1. [ML Service](https://docs.databricks.com/user-guide/libraries.html)\n1. [Cosmos DB](https://azure.microsoft.com/en-us/services/cosmos-db/)\n1. [Container Registery](https://docs.microsoft.com/en-us/azure/container-registry/)\n1. [Container Instances](https://docs.microsoft.com/en-us/azure/container-instances/)\n1. [Application Insights](https://azure.microsoft.com/en-us/services/monitor/)\n1. Storage Account\n1. Key Vault\n\nIn a news recommendation scenario, items have an active lifespan when they should be recommended. After this time has expired old stories are not recommended, and new news stories replace the expired ones. When recommending new stories, only active stories should be recommended. This example shows how to train a model using historical data, and make recommendations for the latest news stories.\n\n\nNew Recommendation Dataset can be found here. http://reclab.idi.ntnu.no/dataset/\n\n##### Citation\nGulla, J. A., Zhang, L., Liu, P., Özgöbek, Ö., & Su, X. (2017, August). The Adressa dataset for news recommendation. In Proceedings of the International Conference on Web Intelligence (pp. 1042-1048). ACM."],
        "metadata": {}
    }, {
        "cell_type": "code",
        "source": ["import pandas as pd\nimport random\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import col, collect_list"],
        "metadata": {},
        "outputs": [{
            "metadata": {},
            "output_type": "display_data",
            "data": {
                "text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]
            }
        }],
        "execution_count": 2
    }, {
        "cell_type": "markdown",
        "source": ["# I. Service Creation"],
        "metadata": {}
    }, {
        "cell_type": "code",
        "source": ["from azure.common.client_factory import get_client_from_cli_profile\n\nimport azureml.core\nfrom azureml.core import Workspace\nfrom azureml.core.run import Run\nfrom azureml.core.experiment import Experiment\n\n\nfrom pyspark.ml import Pipeline, PipelineModel\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.sql import Row\n\nimport numpy as np\nimport os\nimport pandas as pd\nimport pprint\nimport shutil\nimport time, timeit\nimport urllib\nimport yaml\n\n# Check core SDK version number - based on build number of preview/master.\nprint(\"SDK version:\", azureml.core.VERSION)\n\nprefix = \"dcib_igor_\"\nsubscription_id = '03909a66-bef8-4d52-8e9a-a346604e0902'\ndata = 'news'\n\nworkspace_region = \"westus2\"\nresource_group = prefix + \"_\" + data\nworkspace_name = prefix + \"_\"+data+\"_aml\"\nexperiment_name = data + \"_als_Experiment\"\naks_name = \"dcibigoraks\"\nservice_name = \"dcibigoraksals\"\n\n# import the Workspace class and check the azureml SDK version\n# exist_ok checks if workspace exists or not.\nws = Workspace.create(name = workspace_name,\n                      subscription_id = subscription_id,\n                      resource_group = resource_group, \n                      location = workspace_region,\n                      exist_ok=True)\n\n# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\nws.write_config()\n\n# start a training run by defining an experiment\nmyexperiment = Experiment(ws, experiment_name)\nroot_run = myexperiment.start_logging()\n"],
        "metadata": {},
        "execution_count": 4
    }, {
        "cell_type": "markdown",
        "source": ["# II. Training"],
        "metadata": {}
    }, {
        "cell_type": "code",
        "source": ["spark = SparkSession.builder.getOrCreate()\n\ndata = spark.read.json(\"wasb://sampledata@dcibviennadata.blob.core.windows.net/one_week.json\") \\\n  .cache()\n\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml import Pipeline, PipelineModel\n\ndf = data \\\n  .filter(col(\"sessionStart\") != 'true') \\\n  .filter(col(\"sessionStop\") != 'true') \\\n  .filter(col(\"url\") != \"http://adressa.no\") \\\n  .filter(col(\"activeTime\") > 10) \\\n  .select(\"userId\",\"url\", \"activeTime\", \"time\") \\\n  .cache()\n\nindexerContacts = StringIndexer(inputCol='userId', outputCol='userIdIndex', handleInvalid='keep').fit(df)\nindexerRules = StringIndexer(inputCol='url', outputCol='itemIdIndex', handleInvalid='keep').fit(df)\n\nratings = indexerRules.transform(indexerContacts.transform(df)) \\\n  .select(\"userIdIndex\",\"itemIdIndex\",\"activeTime\",\"time\") \\\n  .withColumnRenamed('userIdIndex',\"userId\") \\\n  .withColumnRenamed('itemIdIndex',\"itemId\") \\\n  .withColumnRenamed('activeTime',\"rating\") \\\n  .withColumnRenamed('time',\"timestamp\") \\\n  .cache()\n\ndisplay(ratings.select('userId','itemId','rating','timestamp').orderBy('userId','itemId'))"],
        "metadata": {},
        "execution_count": 6
    }, {
        "cell_type": "code",
        "source": ["display(ratings.select('userId','itemId','rating','timestamp').orderBy('userId','itemId'))"],
        "metadata": {},
        "execution_count": 7
    }, {
        "cell_type": "code",
        "source": ["# Build the recommendation model using ALS on the rating data\n# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\nalgo = ALS(userCol=\"userId\", itemCol=\"itemId\", implicitPrefs=True, coldStartStrategy=\"drop\")\nmodel = algo.fit(ratings)"],
        "metadata": {},
        "execution_count": 8
    }, {
        "cell_type": "code",
        "source": ["# Evaluate the model by computing the RMSE on the rating data\npredictions = model.transform(ratings)\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n                                predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions)\n\nroot_run.log('rmse', rmse)    \nprint(\"Root-mean-square error = \" + str(rmse))"],
        "metadata": {},
        "outputs": [{
            "metadata": {},
            "output_type": "display_data",
            "data": {
                "text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Root-mean-square error = 94.22848622877943\n</div>"]
            }
        }],
        "execution_count": 9
    }, {
        "cell_type": "code",
        "source": ["# Evaluate the model by computing ranking metrics on the rating data\nfrom mmlspark.RankingAdapter import RankingAdapter\nfrom mmlspark.RankingEvaluator import RankingEvaluator\n\noutput = RankingAdapter(mode='allUsers', k=5, recommender=algo) \\\n  .fit(ratings) \\\n  .transform(ratings)\n\nmetrics = ['ndcgAt','map','recallAtK','mrr','fcp']\nmetrics_dict = {}\nfor metric in metrics:\n    metrics_dict[metric] = RankingEvaluator(k=3, metricName=metric).evaluate(output)\n\nfor k in metrics_dict:\n  root_run.log(k, metrics_dict[k])    \n    \nmetrics_dict    "],
        "metadata": {},
        "outputs": [{
            "metadata": {},
            "output_type": "display_data",
            "data": {
                "text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">11</span><span class=\"ansired\">]: </span>\n{&apos;ndcgAt&apos;: 0.38316771123628585,\n &apos;map&apos;: 0.34100844863904206,\n &apos;mrr&apos;: 0.48641892324435054,\n &apos;recallAtK&apos;: 0.18540269574317128,\n &apos;fcp&apos;: 0.21253212250907672}\n</div>"]
            }
        }],
        "execution_count": 10
    }, {
        "cell_type": "code",
        "source": ["# Recommend Subset Wrapper\ndef recommendSubset(self, df, timestamp):\n  def Func(lines):\n    out = []\n    for i in range(len(lines[1])):\n      out += [(lines[1][i],lines[2][i])]\n    return lines[0], out\n\n  tup = StructType([\n    StructField('itemId', IntegerType(), True),\n    StructField('rating', FloatType(), True)\n  ])\n  array_type = ArrayType(tup, True)\n  active_items = df.filter(col(\"timestamp\") > timestamp).select(\"itemId\").distinct()\n  users = df.select(\"userId\").distinct()\n\n  users_active_items = users.crossJoin(active_items)\n  scored = self.transform(users_active_items)\n\n  recs = scored \\\n    .groupBy(col('userId')) \\\n    .agg(collect_list(col(\"itemId\")),collect_list(col(\"prediction\"))) \\\n    .rdd \\\n    .map(Func) \\\n    .toDF() \\\n    .withColumnRenamed(\"_1\",\"userId\") \\\n    .withColumnRenamed(\"_2\",\"recommendations\") \\\n    .select(col(\"userId\"),col(\"recommendations\").cast(array_type))\n\n  return recs\n\nimport pyspark\npyspark.ml.recommendation.ALSModel.recommendSubset = recommendSubset"],
        "metadata": {},
        "outputs": [{
            "metadata": {},
            "output_type": "display_data",
            "data": {
                "text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]
            }
        }],
        "execution_count": 11
    }, {
        "cell_type": "code",
        "source": ["recs = model.recommendSubset(ratings, 1483747200) \\\n  .cache()\n\nrecs.take(5)"],
        "metadata": {},
        "outputs": [{
            "metadata": {},
            "output_type": "display_data",
            "data": {
                "text/html": ["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]
            }
        }],
        "execution_count": 12
    }, {
        "cell_type": "markdown",
        "source": ["In order to turn new stories from cold items, to warm items, 1% of the recommendations servered should include a random new (cold) story. This population should also be used to provide a baseline to measure the online model performance."],
        "metadata": {}
    }, {
        "cell_type": "code",
        "source": ["%%writefile recommend.py\n\nimport pyspark\nfrom pyspark.ml.recommendation import ALS\n\n# Recommend Subset Wrapper\ndef recommendSubset(self, df, timestamp):\n  def Func(lines):\n    out = []\n    for i in range(len(lines[1])):\n      out += [(lines[1][i],lines[2][i])]\n    return lines[0], out\n\n  tup = StructType([\n    StructField('itemId', IntegerType(), True),\n    StructField('rating', FloatType(), True)\n  ])\n  array_type = ArrayType(tup, True)\n  active_items = df.filter(col(\"timestamp\") > timestamp).select(\"itemId\").distinct()\n  users = df.select(\"userId\").distinct()\n\n  users_active_items = users.crossJoin(active_items)\n  scored = self.transform(users_active_items)\n\n  recs = scored \\\n    .groupBy(col('userId')) \\\n    .agg(collect_list(col(\"itemId\")),collect_list(col(\"prediction\"))) \\\n    .rdd \\\n    .map(Func) \\\n    .toDF() \\\n    .withColumnRenamed(\"_1\",\"userId\") \\\n    .withColumnRenamed(\"_2\",\"recommendations\") \\\n    .select(col(\"userId\"),col(\"recommendations\").cast(array_type))\n\n  return recs\n\nimport pyspark\npyspark.ml.recommendation.ALSModel.recommendSubset = recommendSubset\n\n#Implement this function\ndef recommend(historic, timestamp):   \n  algo = ALS(userCol=\"userId\", itemCol=\"itemId\", implicitPrefs=True, coldStartStrategy=\"drop\")\n  model = algo.fit(historic)  \n  recs = model.recommendSubset(historic. timestamp)\n  return recs"],
        "metadata": {},
        "outputs": [],
        "execution_count": 14
    }, {
        "cell_type": "code",
        "source": ["root_run.upload_file(\"outputs/recommend.py\",'recommend.py')\nroot_run.complete()"],
        "metadata": {},
        "outputs": [],
        "execution_count": 15
    }, {
        "cell_type": "markdown",
        "source": ["# III. Scoring"],
        "metadata": {}
    }, {
        "cell_type": "code",
        "source": ["with open('recommend.py', 'r') as myfile:\n    data=myfile.read()\n\nexec(data)\n\nrecs = recommend(ratings,1483747200)\n# display(recs.orderBy('userId'))"],
        "metadata": {},
        "outputs": [],
        "execution_count": 17
    }, {
        "cell_type": "code",
        "source": ["# Register as model\nfrom azureml.core.model import Model\nmymodel = Model.register(model_path = 'recommend.py', # this points to a local file\n                       model_name = 'als', # this is the name the model is registered as, am using same name for both path and name.                 \n                       description = \"ADB trained model by Dan\",\n                       workspace = ws)\n\nprint(mymodel.name, mymodel.description, mymodel.version)"],
        "metadata": {},
        "outputs": [],
        "execution_count": 18
    }, {
        "cell_type": "code",
        "source": ["from azureml.core.model import Model\n\nmymodel = Model.list(ws)[0]\nmymodel.download('./o16n/',exists_ok=True)\nprint(mymodel.name, mymodel.description, mymodel.version)\n\nwith open('./o16n/recommend.py', 'r') as myfile:\n    data=myfile.read()\n\nexec(data)\n\nrecs = recommend(ratings,1692455636)\ndisplay(recs.orderBy('userId'))"],
        "metadata": {},
        "outputs": [],
        "execution_count": 19
    }, {
        "cell_type": "code",
        "source": ["account_name = \"\"\nendpoint = \"https://\" + account_name + \".documents.azure.com:443/\"\nmaster_key = \"\"\n\nwriteConfig = {\n  \"Endpoint\": endpoint,\n  \"Masterkey\": master_key,\n  \"Database\": 'recommendations',\n  \"Collection\": 'news',\n  \"Upsert\": \"true\"\n}\n\n# recs \\\n#   .withColumn(\"id\",recs['userid'].cast(\"string\")) \\\n#   .select(\"id\", \"recommendations.itemid\")\\\n#   .write \\\n#   .format(\"com.microsoft.azure.cosmosdb.spark\") \\\n#   .mode('overwrite') \\\n#   .options(**writeConfig) \\\n#   .save()"],
        "metadata": {},
        "outputs": [],
        "execution_count": 20
    }, {
        "cell_type": "markdown",
        "source": ["# IV. Operationalization"],
        "metadata": {}
    }, {
        "cell_type": "code",
        "source": ["%%writefile score_sparkml.py\n\nimport json\ndef init(local=False):\n    global client, collection\n    try:\n      # Query them in SQL\n      import pydocumentdb.document_client as document_client\n\n      MASTER_KEY = '{key}'\n      HOST = '{endpoint}'\n      DATABASE_ID = \"{database}\"\n      COLLECTION_ID = \"{collection}\"\n      database_link = 'dbs/' + DATABASE_ID\n      collection_link = database_link + '/colls/' + COLLECTION_ID\n      \n      client = document_client.DocumentClient(HOST, {'masterKey': MASTER_KEY})\n      collection = client.ReadCollection(collection_link=collection_link)\n    except Exception as e:\n      collection = e\ndef run(input_json):      \n\n    try:\n      import json\n\n      id = json.loads(json.loads(input_json)[0])['id']\n      query = {'query': 'SELECT * FROM c WHERE c.id = \"' + str(id) +'\"' } #+ str(id)\n\n      options = {}\n\n      result_iterable = client.QueryDocuments(collection['_self'], query, options)\n      result = list(result_iterable);\n  \n    except Exception as e:\n        result = str(e)\n    return json.dumps(str(result)) #json.dumps({{\"result\":result}})"],
        "metadata": {},
        "outputs": [],
        "execution_count": 22
    }, {
        "cell_type": "code",
        "source": ["with open('score_sparkml.py', 'r') as myfile:\n    score_sparkml=myfile.read()\n    \nimport json\nscore_sparkml = score_sparkml.replace(\"{key}\",writeConfig['Masterkey']).replace(\"{endpoint}\",writeConfig['Endpoint']).replace(\"{database}\",writeConfig['Database']).replace(\"{collection}\",writeConfig['Collection'])\n\nexec(score_sparkml)"],
        "metadata": {},
        "outputs": [],
        "execution_count": 23
    }, {
        "cell_type": "code",
        "source": ["%%writefile myenv_sparkml.yml\n\nname: myenv\nchannels:\n  - defaults\ndependencies:\n  - pip:\n    - numpy==1.14.2\n    - scikit-learn==0.19.1\n    - pandas\n    # Required packages for AzureML execution, history, and data preparation.\n    - --extra-index-url https://azuremlsdktestpypi.azureedge.net/sdk-release/Preview/E7501C02541B433786111FE8E140CAA1\n    - azureml-core\n    - pydocumentdb"],
        "metadata": {},
        "outputs": [],
        "execution_count": 24
    }, {
        "cell_type": "code",
        "source": ["models = [mymodel]\nruntime = \"spark-py\"\nconda_file = 'myenv_sparkml.yml'\ndriver_file = \"score_sparkml.py\"\n\n# image creation\nfrom azureml.core.image import ContainerImage\nmyimage_config = ContainerImage.image_configuration(execution_script = driver_file, \n                                    runtime = runtime, \n                                    conda_file = conda_file)\n\nimage = ContainerImage.create(name = \"news-als\",\n                                # this is the model object\n                                models = [mymodel],\n                                image_config = myimage_config,\n                                workspace = ws)\n\n# Wait for the create process to complete\nimage.wait_for_creation(show_output = True)"],
        "metadata": {},
        "outputs": [],
        "execution_count": 25
    }, {
        "cell_type": "code",
        "source": ["#create AKS compute\n#it may take 20-25 minutes to create a new cluster\n\nfrom azureml.core.compute import AksCompute, ComputeTarget\n\n# Use the default configuration (can also provide parameters to customize)\nprov_config = AksCompute.provisioning_configuration()\n\n# Create the cluster\naks_target = ComputeTarget.create(workspace = ws, \n                                  name = aks_name, \n                                  provisioning_configuration = prov_config)\n\naks_target.wait_for_completion(show_output = True)\n\nprint(aks_target.provisioning_state)\nprint(aks_target.provisioning_errors)"],
        "metadata": {},
        "outputs": [],
        "execution_count": 26
    }, {
        "cell_type": "code",
        "source": ["from azureml.core.webservice import Webservice, AksWebservice\nfrom azureml.core.image import ContainerImage\n\n#Set the web service configuration (using default here with app insights)\naks_config = AksWebservice.deploy_configuration(enable_app_insights=True)\n\n# Webservice creation using single command, there is a variant to use image directly as well.\ntry:\n  aks_service = Webservice.deploy_from_image(\n    workspace=ws, \n    name=service_name,\n    deployment_config = aks_config,\n    image = image,\n    deployment_target = aks_target\n      )\n  aks_service.wait_for_deployment(show_output=True)\nexcept Exception:\n    aks_service = Webservice.list(ws)[0]\n"],
        "metadata": {},
        "outputs": [],
        "execution_count": 27
    }, {
        "cell_type": "code",
        "source": ["import urllib\nimport time\nimport json\n\nscoring_url = aks_service.scoring_uri\nservice_key = aks_service.get_keys()[0]\n\ninput_data = '[\"{\\\\\"id\\\\\":\\\\\"1\\\\\"}\"]'.encode()\n\nreq = urllib.request.Request(scoring_url,data=input_data)\nreq.add_header(\"Authorization\",\"Bearer {}\".format(service_key))\nreq.add_header(\"Content-Type\",\"application/json\")\n\ntic = time.time()\nwith urllib.request.urlopen(req) as result:\n    res = result.readlines()\n    print(res)\n    \ntoc = time.time()\nt2 = toc - tic\nprint(\"Full run took %.2f seconds\" % (toc - tic))"],
        "metadata": {},
        "outputs": [],
        "execution_count": 28
    }, {
        "cell_type": "code",
        "source": [""],
        "metadata": {},
        "outputs": [],
        "execution_count": 29
    }],
    "metadata": {
        "name": "News Recommendations - ALS - AML",
        "notebookId": 2996767278517779
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
